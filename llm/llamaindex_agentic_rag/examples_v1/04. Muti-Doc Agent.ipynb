{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ea1c2b",
   "metadata": {},
   "source": [
    "# LlamaIndex: Building Multi-Document Agent\n",
    "\n",
    "Below are experiments in agent reasoning over multiple documents.\n",
    "\n",
    "Please reference this [DeepLearning.AI](https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/lesson/nfa5y/building-a-multi-document-agent) course for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c57a7",
   "metadata": {},
   "source": [
    "### Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d02cbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.36\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import llama_index\n",
    "import os\n",
    "import httpx\n",
    "from pathlib import Path\n",
    "import textwrap \n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "from tools_util import get_doc_tools\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "llm = OpenAI(model=\"o4-mini\", temperature=0)\n",
    "\n",
    "print(llama_index.core.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a97837",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9914b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2505_10543', './data/2505.10543.pdf'), ('2505_11423', './data/2505.11423.pdf'), ('2505_13259', './data/2505.13259.pdf')]\n"
     ]
    }
   ],
   "source": [
    "files = ['https://arxiv.org/pdf/2505.10543', 'https://arxiv.org/pdf/2505.11423', 'https://arxiv.org/pdf/2505.13259' ]\n",
    "\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "papers = []\n",
    "\n",
    "for f in files:\n",
    "    file_name =  Path(f).name\n",
    "    file_path = f\"./data/{file_name}.pdf\"\n",
    "    if not os.path.exists(file_path):\n",
    "        r = httpx.get(f, timeout=20)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    papers.append((file_name.replace(\".\", \"_\"), file_path))\n",
    "print(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb0d4ed",
   "metadata": {},
   "source": [
    "### Create the Query Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1461453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: 2505_10543\n",
      "Getting tools for paper: 2505_11423\n",
      "Getting tools for paper: 2505_13259\n"
     ]
    }
   ],
   "source": [
    "paper_to_tools_dict = {}\n",
    "for name, path in papers:\n",
    "    print(f\"Getting tools for paper: {name}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(path, name)\n",
    "    paper_to_tools_dict[name] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6076824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2505_10543', '2505_11423', '2505_13259'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_to_tools_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dcd53",
   "metadata": {},
   "source": [
    "When creating the LlamaIndex query engine in the `tools_util.get_doc_tools` function, I use the summary index query engine to create a once sentence description of the document the tools are build for. This was done to give the Agent Runner as more information when selecting the tool to be used to answer the question. Below is the description that was synthesized for one of the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042550a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful for summarization questions related to this document which is about: The document delves into the increasing roles of Large Language\n",
      "Models (LLMs) in scientific research, categorizing their functions as Tools, Analysts, and Scientists, while discussing challenges and\n",
      "future prospects in AI-driven scientific exploration.\n"
     ]
    }
   ],
   "source": [
    "wrapped_text = textwrap.fill(paper_to_tools_dict['2505_13259'][1].metadata.description, \n",
    "                             width=140, replace_whitespace=False)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16addd18",
   "metadata": {},
   "source": [
    "### Create The Agent runner and worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696ca8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tools = [t for name, _ in papers for t in paper_to_tools_dict[name]]\n",
    "assert len(initial_tools) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c759ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    initial_tools, \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab326b",
   "metadata": {},
   "source": [
    "### Submit a Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e336b",
   "metadata": {},
   "source": [
    "Below, a query is submitted using a prompt that only the document `2505.13259.pdf` entitled \"From Automation to Autonomy:\n",
    "A Survey on Large Language Models in Scientific Discovery\" would be able to answer. Lets see if the agent selected the right tool for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e1b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What are the levels of autonomy when Large Language models are used for scientific research.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_query_engine_2505_13259 with args: {\"input\": \"levels of autonomy\"}\n",
      "=== Function Output ===\n",
      "LLMs in scientific discovery progress through three levels of autonomy:  \n",
      "1. LLM as Tool: Foundational application where LLMs function as tools under human supervision to automate specific tasks within a single stage of the scientific method.  \n",
      "2. LLM as Analyst: LLMs exhibit greater autonomy in processing complex information, conducting analyses, and offering insights with reduced human intervention for intermediate steps.  \n",
      "3. LLM as Scientist: LLM-based systems operate as active agents capable of orchestrating and navigating multiple stages of the scientific discovery process with considerable independence, driving substantial portions of the research cycle with minimal human intervention.\n",
      "=== LLM Response ===\n",
      "The paper describes three escalating levels of autonomy for LLMs in scientific research:\n",
      "\n",
      "1. LLM as Tool  \n",
      "   - The model is used under direct human control to automate well‐defined, narrowly scoped tasks (e.g., literature search, summarization, data cleaning).  \n",
      "   - Human scientists design the experiments, choose methods, interpret results, and make all final decisions.  \n",
      "\n",
      "2. LLM as Analyst  \n",
      "   - The model takes on more complex, multi‐step analyses and offers interpretations (e.g., hypothesis generation, intermediate data analysis, preliminary model fitting).  \n",
      "   - Humans still supervise, vet outputs, and guide the overall workflow, but the LLM can suggest next steps and evaluate partial results.  \n",
      "\n",
      "3. LLM as Scientist  \n",
      "   - The model operates as an active research agent: autonomously designing experiments, running simulations or analyses, interpreting results, and iterating on hypotheses.  \n",
      "   - Human involvement is minimal—primarily high‐level oversight, validation of conclusions, and ethical/safety checks.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"What are the levels of autonomy when Large Language models are used for scientific research.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ad794",
   "metadata": {},
   "source": [
    "The results look correct. Now lets try getting information from two of the documents. The expected tools used will be those for:\n",
    "\n",
    "1. Document `2505.11423.pdf`: \"When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs\".\n",
    "2. Document `2505.13259.pdf`: \"From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64664325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: For Large Language Models, summarize the pitfalls of reasoning and levels of autonomy for scientific research.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_query_engine_2505_11423 with args: {\"input\": \"pitfalls of reasoning in LLMs\"}\n",
      "=== Function Output ===\n",
      "The pitfalls of reasoning in large language models (LLMs) include overemphasizing high-level content at the expense of simple mechanical constraints, introducing unnecessary content that violates constraints, and potentially leading to failures in meeting specific requirements. Additionally, reasoning may inadvertently break constraints by introducing elements that deviate from the desired output, such as violating punctuation rules or language restrictions. While reasoning can aid in organizing content more effectively, it can also distract from strict constraint control, resulting in failures to meet all specified criteria.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_query_engine_2505_13259 with args: {\"input\": \"levels of autonomy for scientific research\"}\n",
      "=== Function Output ===\n",
      "The levels of autonomy for scientific research are categorized into three stages: as a tool, as an analyst, and as a scientist. These levels progress from functioning as a tool under direct human supervision to operating as a passive agent with reduced human intervention for more complex tasks, and finally to functioning as an active agent capable of independently orchestrating and navigating multiple stages of the scientific discovery process.\n",
      "=== LLM Response ===\n",
      "Here’s a concise summary:\n",
      "\n",
      "1. Pitfalls of Reasoning in LLMs  \n",
      "   • Over-emphasis on high-level or “clever” content can come at the expense of simple, mechanical constraints (e.g., exact phrasing, punctuation, or formatting).  \n",
      "   • Reasoning chains may introduce unnecessary or extraneous information that violates strict requirements (language, length, style).  \n",
      "   • The added complexity of explicit reasoning can distract the model from following hard constraints, leading to failures of compliance.  \n",
      "   • In some cases, “thinking out loud” helps structure an answer, but it can also derail adherence to simple but critical instructions.\n",
      "\n",
      "2. Levels of Autonomy for LLM-Driven Scientific Research  \n",
      "   • Tool: Operates under tight human supervision, performing narrowly defined tasks (data retrieval, basic analysis).  \n",
      "   • Analyst: Acts as a passive agent with less direct oversight, handling more complex or multi-step analyses as directed.  \n",
      "   • Scientist: Functions as an active, independent agent capable of orchestrating and navigating multiple stages of the scientific workflow (hypothesis generation, experiment design, data interpretation) with minimal human intervention.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"For Large Language Models, summarize the pitfalls of reasoning and levels of autonomy for scientific research.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf5678",
   "metadata": {},
   "source": [
    "The results are as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03552f5",
   "metadata": {},
   "source": [
    "### Limiting The Number of Tools Used to Answer A Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc689d",
   "metadata": {},
   "source": [
    "A Tool Retriever enables limiting the tools used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba17ed6",
   "metadata": {},
   "source": [
    "First the tools are indexed. The tools are serialized bdelow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07f55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "all_tools = [t for name, _ in papers for t in paper_to_tools_dict[name]]\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c57106",
   "metadata": {},
   "source": [
    "Now an object retriever is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24f989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe83c0",
   "metadata": {},
   "source": [
    "Lets experiment by providing a very generic question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f23a7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = obj_retriever.retrieve(\n",
    "    \"Tell me something about LLMs.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5fe1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "summary_query_engine_2505_13259\n",
      "vector_query_engine_2505_13259\n"
     ]
    }
   ],
   "source": [
    "print(len(tools))\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715836d1",
   "metadata": {},
   "source": [
    "This looks correct: Two tools were returned when all the papers could have been used to answer the question.\n",
    "\n",
    "Now create a function calling agent that uses the object retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f2c529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given documents.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1287252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Describe the reasoning-enhanced large language models and large language models in scientific discovery.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_query_engine_2505_13259 with args: {\"input\": \"Describe large language models in scientific discovery\"}\n",
      "=== Function Output ===\n",
      "Large language models play a crucial role in scientific discovery by assisting researchers in tasks such as literature search, hypothesis formulation, experiment planning, data analysis, and conclusion validation across various domains. These models are evolving to become increasingly autonomous agents, integrating advanced capabilities like planning, complex reasoning, and instruction following. They are utilized at different levels of autonomy, transitioning from tools for task automation to analysts for data modeling and analysis, and eventually to scientists capable of autonomously conducting major research stages. The future of large language models in scientific discovery involves challenges such as achieving fully autonomous research cycles, integrating robotic automation for physical experiments, ensuring transparency and interpretability, continuous self-improvement, and addressing ethical and societal alignment issues.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_query_engine_2505_11423 with args: {\"input\": \"Describe reasoning-enhanced large language models\"}\n",
      "=== Function Output ===\n",
      "Reasoning-enhanced large language models are designed to incorporate explicit reasoning capabilities, enabling them to perform complex tasks by following a chain-of-thought prompting approach. These models engage in step-by-step thinking and logical processing to analyze instructions, constraints, and conditions provided in a prompt before generating a response. By reasoning through tasks, they aim to better understand requirements and produce answers that adhere closely to specified constraints, ultimately improving task performance by making informed decisions on utilizing additional context or logic to enhance responses.\n",
      "=== LLM Response ===\n",
      "Reasoning-Enhanced Large Language Models  \n",
      "These are LLMs augmented with explicit, chain-of-thought reasoning to improve their ability to follow complex instructions and respect detailed constraints. Rather than generating answers directly, they:  \n",
      "• Break down a task into intermediate steps  \n",
      "• Logically process conditions and edge cases  \n",
      "• Decide when and how to bring in additional context (e.g., external facts or intermediate calculations)  \n",
      "By simulating a step-by-step “inner monologue,” they more reliably satisfy requirements—avoiding oversights that purely end-to-end models can make—and often produce more accurate, constraint-compliant outputs on challenging tasks.  \n",
      "\n",
      "Large Language Models in Scientific Discovery  \n",
      "LLMs are rapidly moving from “smart text engines” to active partners in research. Their roles span three broad levels of autonomy:  \n",
      "1. Task Automation (“Tools”)  \n",
      "   – Accelerate literature search, draft hypotheses, write and debug code for data processing or experiment control.  \n",
      "2. Data Analysis & Modeling (“Analysts”)  \n",
      "   – Design experiments in silico, build and interpret statistical or mechanistic models, mine large datasets for patterns, and validate conclusions.  \n",
      "3. Autonomous Discovery (“Scientists”)  \n",
      "   – Integrate planning, complex reasoning, and even closed-loop experimentation (potentially via robotics) to formulate hypotheses, run experiments, analyze results, and iterate with minimal human intervention.  \n",
      "\n",
      "Key challenges and future directions include:  \n",
      "• Closing the loop on fully autonomous research cycles—linking LLM planning directly to automated labs or simulation platforms  \n",
      "• Ensuring transparency and interpretability so that LLM-derived hypotheses and analyses can be critically evaluated  \n",
      "• Building continuous self-improvement mechanisms, allowing models to learn from new data and experiment outcomes  \n",
      "• Addressing ethical, safety, and societal alignment issues, especially as LLMs take on more decision-making responsibility in high-stakes domains.\n"
     ]
    }
   ],
   "source": [
    "agent.memory.reset()\n",
    "response = agent.query(\"Describe the reasoning-enhanced large language models and large language models in scientific discovery.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
