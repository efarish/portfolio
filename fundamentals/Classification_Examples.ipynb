{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd0c37a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Below a classification task is performed on a credit card fraud Kaggle dataset. The following algorithms are used for this task:\n",
    "\n",
    "- Support Vector Classifier\n",
    "- Decision Tree \n",
    "- Multi-Layer Perceptron\n",
    "- Random Forest \n",
    "- PyTorch MLP\n",
    "\n",
    "# Explore the dataset\n",
    "\n",
    "Per its __[Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)__ website, the dataset contains credit card transactions that are labeled as genuine or fraudulent. Below, the dataset is loaded and its meta-data displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb4fd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (284807, 31)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./creditcard.csv')\n",
    "print(f'Shape: {data.shape}',end='\\n\\n')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd79307",
   "metadata": {},
   "source": [
    "All of the data is numeric and none of the data is missing.\n",
    "\n",
    "## Class balance\n",
    "\n",
    "Below is the target variable's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3627821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Distribution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284315</td>\n",
       "      <td>0.998273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Frequency  Distribution\n",
       "Class                         \n",
       "0         284315      0.998273\n",
       "1            492      0.001727"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Frequency':data['Class'].value_counts().sort_index().sort_index(),\n",
    "                            'Distribution':data['Class'].value_counts(normalize=True).sort_index()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69fa044",
   "metadata": {},
   "source": [
    "The target variable `Class` is binary and very imbalanced. There are only $\\approx$ 0.2% positive examples. Therefore, the cost metric `F1 Score` will be used to evaluate models developed using the dataset.\n",
    "\n",
    "\n",
    "## Normalization or standardization?\n",
    "\n",
    "The dataset's `V*` variables are the result of a PCA transformation and don't need standardization. Reviewing their standard deviations, the PCA variable names appear to capture the explained variance of each feature in decreasing order. \n",
    "\n",
    "The variance explained by the first 25 of the 28 components is calculated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a103f03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8587489339504131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_summary_stats = data.iloc[:,1:29].describe()\n",
    "pca_sum_var = pca_summary_stats.loc['std'].pow(2).sum()\n",
    "sum(pca_summary_stats.loc['std'].iloc[1:25,].pow(2)/pca_sum_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a43f39",
   "metadata": {},
   "source": [
    "The first 25 components explain about $\\approx$ 86% of the variance. For this analysis, all the PCA components will be included in the models developed. \n",
    "\n",
    "The  `Amount` and `Time` fields require standardization. A standard scaler will be used on the `Amount` variable.   \n",
    "\n",
    "The `Time` variable contains the seconds elapsed between each transaction and the first transaction in the dataset. If I had some way of associating the transactions, this might be useful. As I can't, I will exclude the `Time` variable from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc59506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.913952e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-0.33084</td>\n",
       "      <td>-0.265271</td>\n",
       "      <td>-0.044717</td>\n",
       "      <td>102.362243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean       std       min      25%       50%  \\\n",
       "Amount  284807.0  2.913952e-17  1.000002 -0.353229 -0.33084 -0.265271   \n",
       "\n",
       "             75%         max  \n",
       "Amount -0.044717  102.362243  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,1:30] # Exclude Time variable.\n",
    "y = data.iloc[:,30]\n",
    "\n",
    "# Standardize Amount.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X[['Amount']] = StandardScaler().fit_transform(X[['Amount']])\n",
    "X[['Amount']].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc745ed",
   "metadata": {},
   "source": [
    "The scaled `Amount` looks correct.\n",
    "\n",
    "## Split the dataset & model testing\n",
    "\n",
    "The 50/50 split of training and test data is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1c5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.50, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6739d",
   "metadata": {},
   "source": [
    "The code below performs hyper-parameter grid searches using SVC, Decision Tree, MLP, and Random Forest algorithms. A 10-fold CV is done to determine the best estimator for each grid search. Using the best estimator, the F1 scores are calculated. For each algorithm, a non-regularized and a regularized grid search is done.\n",
    "\n",
    "# Classifier: SVC\n",
    "\n",
    "Below, SVM classifier is fitted using the default regularization parameters and its performance calculated. This model and the ones that follow were fitted using a AWS `c6a.24xlarge` EC2 instance using 95 of its 96 CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d84619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "number_of_jobs=95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09a12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "Reclassification score: 0.8991228070175439\n",
      "Test score: 0.7593052109181141\n",
      "CPU times: user 1min 17s, sys: 776 ms, total: 1min 17s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = [{'C': [1]}]\n",
    "gs = GridSearchCV(SVC(kernel='rbf'), param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# find best model score\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d991ce1",
   "metadata": {},
   "source": [
    "To regularize the SVM, a grid search will be performed using the two hyper-parameters below:\n",
    "\n",
    "- The `C` regularization parameter controls the strength of the `l2` penalty added to the algorithm's objective function.\n",
    "- The `gamma` ($\\gamma$) parameter is a multiplier that is applied as a regularization parameter within the kernel calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177e81d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.9, 'gamma': 'scale'}\n",
      "Reclassification score: 0.9379014989293363\n",
      "Test score: 0.7990314769975787\n",
      "CPU times: user 1min 4s, sys: 498 ms, total: 1min 4s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = [{'gamma': ['scale','auto'], 'C': [2.8, 2.9, 3, 3.1]}]\n",
    "gs = GridSearchCV(SVC(kernel='rbf'), param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# Find best model score...\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9268bd1",
   "metadata": {},
   "source": [
    "Displayed above are the hyper-parameters of the best performing estimator. Comparing the performance of the two models, the regularized SVM model generalized better on the test data.\n",
    "\n",
    "# Classifier: Decision Tree\n",
    "\n",
    "Below an un-pruned decision tree is fitted and evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "191a6613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'}\n",
      "Reclassification score: 1.0\n",
      "Test score: 0.7276595744680852\n",
      "CPU times: user 6.15 s, sys: 142 ms, total: 6.29 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "params = [{'criterion':['gini', 'entropy']}]\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# Find best model score...\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fc9b1",
   "metadata": {},
   "source": [
    "Next a pruned tree is fitted using `sklearn's` implementation of Minimal Cost-Complexity Pruning, an algorithm used to prune a tree to avoid over-fitting. The pruning occurs such that the subtree with the largest cost complexity that is smaller than ccp_alpha hyper-parameter will be chosen. To help select the best alpha value for the tree, the code below computes the pruning path during a Minimal Cost-Complexity pruning of a tree. These values will be used in the grid search that follows to find an optimal `ccp_alpha` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918a54ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 34.2 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "path = clf.cost_complexity_pruning_path(X_tr, y_tr)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "restult = ax.set_title(\"Total Impurity vs effective alpha for training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f93d6b",
   "metadata": {},
   "source": [
    "The alphas calculated above will now be used in a grid search to find the best estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a3ddca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 6.870347409444549e-05, 'criterion': 'entropy'}\n",
      "Reclassification score: 0.8812095032397409\n",
      "Test score: 0.7847533632286996\n",
      "CPU times: user 7.99 s, sys: 810 ms, total: 8.8 s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = [{'ccp_alpha': ccp_alphas, 'criterion':['gini', 'entropy']}]\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# Find best model score...\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8edb7",
   "metadata": {},
   "source": [
    "While the reclassification `F1 Score` is lower for the pruned decision tree, its test score is higher than the un-pruned tree.\n",
    "\n",
    "# Classifier: MLP Classifier\n",
    "\n",
    "Below, a non-regularized MLP is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ebe019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0, 'batch_size': 200, 'learning_rate_init': 0.001, 'max_iter': 100}\n",
      "Reclassification score: 0.9120654396728016\n",
      "Test score: 0.8134171907756813\n",
      "CPU times: user 12.2 s, sys: 10.7 s, total: 22.9 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "params = [{'max_iter': [100, 500, 1000, 2000], \n",
    "           'learning_rate_init':[0.1, 0.01, 0.001, 0.0001], 'alpha':[0],\n",
    "           'batch_size': [100, 200, 500]}]\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(28,10), random_state=0)\n",
    "gs = GridSearchCV(mlp, param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# Find best model score...\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20675911",
   "metadata": {},
   "source": [
    "Now a regularized grid search will be performed using the `sklearn` MLP implementation's `alpha` hyper-parameter. This parameter determines the strength of the `L2` regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cdd288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'batch_size': 200, 'learning_rate_init': 0.001, 'max_iter': 100}\n",
      "Reclassification score: 0.8945147679324894\n",
      "Test score: 0.8366013071895425\n",
      "CPU times: user 15.8 s, sys: 14.5 s, total: 30.3 s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = [{'max_iter': [100, 500, 1000, 2000], \n",
    "           'learning_rate_init':[0.1, 0.01, 0.001, 0.0001], 'alpha':[0.01, 0.001, 0.0001],\n",
    "           'batch_size': [100, 200, 500]}]\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(28,10), random_state=0)\n",
    "gs = GridSearchCV(mlp, param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# Find best model score...\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f79bd",
   "metadata": {},
   "source": [
    "The hyper-parameters and performance of the best estimator are displayed above. Once again, the regularized model has better generalized performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f87e0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_best_clf = gs.best_estimator_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85cbcaf",
   "metadata": {},
   "source": [
    "# Classifier: Random Forest Classifier\n",
    "\n",
    "Below a non-pruned Random Forest classifier is fitted and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c0b80da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'n_estimators': 100}\n",
      "Reclassification score: 0.9473684210526316\n",
      "Test score: 0.8240534521158129\n",
      "CPU times: user 1min 1s, sys: 2.15 s, total: 1min 3s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def getRFModel(_estimators, _depth, _random_state=0, _alpha=0.0, _jobs=None):\n",
    "    return  RandomForestClassifier(n_estimators=_estimators, max_depth=_depth, \n",
    "                                   criterion=\"entropy\", class_weight=\"balanced_subsample\", \n",
    "                                   random_state=_random_state, n_jobs=_jobs, ccp_alpha=_alpha) \n",
    "\n",
    "params = [{'n_estimators': [10, 100, 200], 'max_depth': [None, 8, 9, 10, 11]}]\n",
    "gs = GridSearchCV(getRFModel(100, 10, 0, _alpha=0, _jobs=4), param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# Find best model score...\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84fee3",
   "metadata": {},
   "source": [
    "Next, using the best best performing `ccp_alpha` found in the Decision Tree grid search, a regularized model is evaluated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd8ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 6.870347409444549e-05, 'max_depth': 9, 'n_estimators': 100}\n",
      "Reclassification score: 0.9435483870967742\n",
      "Test score: 0.8325991189427313\n",
      "CPU times: user 58.3 s, sys: 264 ms, total: 58.5 s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = [{'n_estimators': [10, 100, 200], 'max_depth': [None, 8, 9, 10, 11], 'ccp_alpha':[6.870347409444549e-05]}]\n",
    "gs = GridSearchCV(getRFModel(100, 10, 0, _alpha=0, _jobs=4), param_grid=params, scoring='f1', cv=10, n_jobs=number_of_jobs)\n",
    "gs.fit(X_tr, y_tr)\n",
    "# Get best parameters...\n",
    "print(gs.best_params_)\n",
    "# Find best model score...\n",
    "print(f'Reclassification score: {gs.score(X_tr, y_tr)}')\n",
    "print(f'Test score: {gs.score(X_ts, y_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a7145",
   "metadata": {},
   "source": [
    "As expected, the regularized RFC performs better than the non-regularized model, although the difference is small.\n",
    "\n",
    "Next, a 10-fold CV is done using the best regularized Random Forest estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d045366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_clf = gs.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea7b9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def eval_classifier(_clf, _X, _y, _niter, return_metrics=False, debug=False):\n",
    "    accs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    for i in range(_niter):\n",
    "        kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=i)\n",
    "        split = 1\n",
    "        for tr_ix, ts_ix in kf.split(_X, _y):\n",
    "            _clf.fit(_X[tr_ix], _y[tr_ix])\n",
    "            y_pred = _clf.predict(_X[ts_ix])\n",
    "            accs       += [accuracy_score (_y[ts_ix], y_pred)]\n",
    "            precisions += [precision_score(_y[ts_ix], y_pred, zero_division=0)]\n",
    "            recalls    += [recall_score   (_y[ts_ix], y_pred)]\n",
    "            f1s        += [f1_score       (_y[ts_ix], y_pred)]\n",
    "            if debug: print(f'Iteration {i}, Finished split {split}',end='\\r')\n",
    "            split += 1    \n",
    "        if debug: print(' ' * 50, end='\\r')            \n",
    "    \n",
    "    if return_metrics: \n",
    "        return [np.mean(accs),np.mean(precisions),np.mean(recalls),np.mean(f1s)]\n",
    "    else:\n",
    "        print(f'Stratified 10-Fold CV with {_niter} iterations')        \n",
    "        print(f' Accuracy = {np.mean(accs):.3f} {chr(177)}{np.std(accs):.4f},', end =\"\")\n",
    "        print(f' Precision = {np.mean(precisions):.3f} {chr(177)}{np.std(precisions):.4f},', end =\"\")\n",
    "        print(f' Recall = {np.mean(recalls):.3f} {chr(177)}{np.std(recalls):.4f},', end =\"\")\n",
    "        print(f' F1 Score = {np.mean(f1s):.3f} {chr(177)}{np.std(f1s):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b9218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10-Fold CV with 1 iterations           \n",
      " Accuracy = 1.000 ±0.0001, Precision = 0.909 ±0.0475, Recall = 0.796 ±0.0721, F1 Score = 0.845 ±0.0338\n"
     ]
    }
   ],
   "source": [
    "eval_classifier(rf_best_clf, X_tr.values, y_tr.values, 1, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34805164",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "Regularization improved the performance of all the models. The regularized MLP had the best generalized performance with a test data `F1 Score`of $\\approx$ 83.7%. Close behind was the regularized Random Forest Decision Tree at $\\approx$ 83.3%. \n",
    "\n",
    "\n",
    "# Classifier: PyTorch neural network\n",
    "\n",
    "Below, a ANN with two hidden layers is evaluated. The PyTorch code below came from Module 10's instructor provided notebook. However, I have modified the code to use a GPU (if its available) and changed all the activation functions to `ReLU`. The models were built on an AWS `p3.2xlarge` EC2 instance with 1 GPU and 8 CPUs. \n",
    "\n",
    "First, the data is reloaded as the code below was run on a different EC2 instance than the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3162930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./creditcard.csv')\n",
    "X = data.iloc[:,1:30] # Exclude Time variable.\n",
    "y = data.iloc[:,30]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X[['Amount']] = StandardScaler().fit_transform(X[['Amount']])\n",
    "X[['Amount']].describe().transpose()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.50, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b80eb",
   "metadata": {},
   "source": [
    "The training and test are converted to PyTorch tensors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee450b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "X_tr_ten = torch.FloatTensor(X_tr.values)\n",
    "y_tr_ten = torch.LongTensor(y_tr.values)\n",
    "X_ts_ten = torch.FloatTensor(X_ts.values)\n",
    "y_ts_ten = torch.LongTensor(y_ts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f8fb6",
   "metadata": {},
   "source": [
    "The code below confirms `CUDA` is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c120a719-efc1-4d90-b46e-5a18eb8828bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 2.0.1\n",
      "CUDA available= False\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')  # CUDA optional - True when GPU present, CUDA installed\n",
    "device_type = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485595d2",
   "metadata": {},
   "source": [
    "Now, lets confirm a GPU is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e5c577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of GPUs: {torch.cuda.device_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500d63d",
   "metadata": {},
   "source": [
    "Below is the `PyTorchMLP` ANN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69461076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PyTorchMLP(torch.nn.Module):  \n",
    "    def __init__(self, n_hidden=10, epochs=100, eta=0.001, minibatch_size=50, seed=0):\n",
    "        super(PyTorchMLP, self).__init__()\n",
    "        self.random = np.random.RandomState(seed)  # shuffle mini batches\n",
    "        self.n_hidden = n_hidden  # size of the hidden layer\n",
    "        self.epochs = epochs  # number of iterations\n",
    "        self.eta = eta  # learning rate\n",
    "        self.minibatch_size = minibatch_size  # size of training batch - 1 would not work\n",
    "        self.optimizer = None\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        self.model = None\n",
    "\n",
    "    def init_layers(self, _M:int, _K:int) -> None:\n",
    "        # data structure\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(_M, self.n_hidden).to(device_type), #self.n_hidden\n",
    "            torch.nn.ReLU().to(device_type),\n",
    "            torch.nn.Linear(self.n_hidden, self.n_hidden).to(device_type),\n",
    "            torch.nn.ReLU().to(device_type),\n",
    "            torch.nn.Linear(self.n_hidden, _K).to(device_type),\n",
    "        )\n",
    "    \n",
    "    def predict(self, _X):\n",
    "        _X = _X.to(device_type, non_blocking=True)\n",
    "        assert self.model is not None\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = np.argmax(self.model(_X).cpu(), axis=1)\n",
    "        self.model.train()\n",
    "        return y_pred.numpy()\n",
    "\n",
    "    def fit(self, _X_train, _y_train, info=False):\n",
    "        import sys\n",
    "        \n",
    "        _X_train = _X_train.to(device_type, non_blocking=True)\n",
    "        _y_train = _y_train.to(device_type, non_blocking=True).long()\n",
    "        \n",
    "        n_features= _X_train.shape[1]\n",
    "        n_output= 2 #np.unique(_y_train).shape[0]  # number of class labels CHANGE\n",
    "        \n",
    "        self.init_layers(n_features, n_output)\n",
    "        self.optimizer = torch.optim.Rprop(self.model.parameters(), lr=self.eta)  # connect model to optimizer\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            print(f'Epoc {i}...',end='\\r')\n",
    "            \n",
    "            indices = np.arange(_X_train.shape[0])\n",
    "            self.random.shuffle(indices)  # shuffle the data each epoch\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                net_out = self.model(_X_train[batch_idx])\n",
    "                \n",
    "                loss = self.loss_func(net_out, _y_train[batch_idx])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                if info:\n",
    "                    sys.stderr.write(f\"\\r{i+1:03d} Loss: {loss.item():6.5f}\")\n",
    "                    sys.stderr.flush()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cc36ad",
   "metadata": {},
   "source": [
    "Below, a un-regularized ANN is evaluated. I did not have enough time to implement a search grid using PyTorch code. Therefore, the hyper-parameters below selected after a few rounds of pilot testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745f4224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassification scores: 0.8316\n",
      "Test score: 0.8043\n",
      "CPU times: user 4.28 s, sys: 811 ms, total: 5.1 s\n",
      "Wall time: 5.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp1 = PyTorchMLP(n_hidden=20, epochs=100, eta=0.001, minibatch_size=12000)\n",
    "mlp1 = mlp1.to(device_type)\n",
    "mlp1 = mlp1.fit(X_tr_ten, y_tr_ten)\n",
    "print(f'Reclassification scores: {round(f1_score(y_tr, mlp1.predict(X_tr_ten)),4)}')\n",
    "print(f'Test score: {round(f1_score(y_ts, mlp1.predict(X_ts_ten)),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51552a",
   "metadata": {},
   "source": [
    "## Add Dropouts\n",
    "\n",
    "Below, the ANN is regularized using a dropout probability of 10% after each hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2e76f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassification scores: 0.8298\n",
      "Test score: 0.8017\n",
      "CPU times: user 3.22 s, sys: 43.6 ms, total: 3.27 s\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A derived class to have Dropout\n",
    "class MLP2(PyTorchMLP):\n",
    "    def init_layers(self, _M, _K):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(_M, self.n_hidden).to(device_type),\n",
    "            torch.nn.ReLU().to(device_type),\n",
    "            torch.nn.Dropout(0.1).to(device_type),\n",
    "            torch.nn.Linear(self.n_hidden, self.n_hidden).to(device_type),\n",
    "            torch.nn.ReLU().to(device_type),\n",
    "            torch.nn.Dropout(0.1).to(device_type),\n",
    "            torch.nn.Linear(self.n_hidden, _K).to(device_type),\n",
    "        )\n",
    "\n",
    "mlp2 = MLP2(n_hidden=20, epochs=100, eta=0.001, minibatch_size=12000)\n",
    "mlp2 = mlp2.to(device_type)\n",
    "mlp2 = mlp2.fit(X_tr_ten, y_tr_ten)\n",
    "print(f'Reclassification scores: {round(f1_score(y_tr, mlp2.predict(X_tr_ten)),4)}')\n",
    "print(f'Test score: {round(f1_score(y_ts, mlp2.predict(X_ts_ten)),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbc883",
   "metadata": {},
   "source": [
    "Interestingly, the regularization did not result in better generalized performance. Mostly likely, grid search performance tuning would improve this.\n",
    "\n",
    "## Performance Summary: 10-fold cross validation\n",
    "\n",
    "As reported above, the 10-fold CV `F1 Score` for the regularized Random Forest was $\\approx$ 84.5%.\n",
    "\n",
    "Below, the CV performance is calculated for the two PyTorch ANNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bea473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def eval_classifier(_clf, _X, _y, _niter, return_metrics=False, debug=False):\n",
    "    accs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    for i in range(_niter):\n",
    "        kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=i)\n",
    "        split = 1\n",
    "        for tr_ix, ts_ix in kf.split(_X, _y):\n",
    "            _clf.fit(_X[tr_ix], _y[tr_ix])\n",
    "            y_pred = _clf.predict(_X[ts_ix])\n",
    "            accs       += [accuracy_score (_y[ts_ix], y_pred)]\n",
    "            precisions += [precision_score(_y[ts_ix], y_pred, zero_division=0)]\n",
    "            recalls    += [recall_score   (_y[ts_ix], y_pred)]\n",
    "            f1s        += [f1_score       (_y[ts_ix], y_pred)]\n",
    "            if debug: print(f'Iteration {i}, Finished split {split}',end='\\r')\n",
    "            split += 1    \n",
    "        if debug: print(' ' * 50, end='\\r')            \n",
    "    \n",
    "    if return_metrics: \n",
    "        return [np.mean(accs),np.mean(precisions),np.mean(recalls),np.mean(f1s)]\n",
    "    else:\n",
    "        print(f'Stratified 10-Fold CV with {_niter} iterations')        \n",
    "        print(f' Accuracy = {np.mean(accs):.3f} {chr(177)}{np.std(accs):.4f},', end =\"\")\n",
    "        print(f' Precision = {np.mean(precisions):.3f} {chr(177)}{np.std(precisions):.4f},', end =\"\")\n",
    "        print(f' Recall = {np.mean(recalls):.3f} {chr(177)}{np.std(recalls):.4f},', end =\"\")\n",
    "        print(f' F1 Score = {np.mean(f1s):.3f} {chr(177)}{np.std(f1s):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8224a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10-Fold CV with 1 iterations           \n",
      " Accuracy = 0.999 ±0.0002, Precision = 0.843 ±0.0719, Recall = 0.788 ±0.0749, F1 Score = 0.810 ±0.0451\n"
     ]
    }
   ],
   "source": [
    "eval_classifier(mlp1, X_tr_ten, y_tr_ten, 1, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b90af76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10-Fold CV with 1 iterations           \n",
      " Accuracy = 0.999 ±0.0001, Precision = 0.845 ±0.0703, Recall = 0.767 ±0.0921, F1 Score = 0.798 ±0.0454\n"
     ]
    }
   ],
   "source": [
    "eval_classifier(mlp2, X_tr_ten, y_tr_ten, 1, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4948d",
   "metadata": {},
   "source": [
    "The Random Forest has a significantly better CV `F1 Score`. However, as mentioned, the ANN performance could be improved with some hyper-parameter tunning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a208dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
